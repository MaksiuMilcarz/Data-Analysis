{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92b26bc",
   "metadata": {},
   "source": [
    "Group 35\n",
    "\n",
    "Bruna Cavalcanti Lauro\n",
    "\n",
    "i6344286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c750f0",
   "metadata": {},
   "source": [
    "**Use of genAI tools (e.g. chatGPT), websites (e.g. stackoverflow)**: *list websites where you found code (or other info) as well as include information on how you used genAI tools*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008fc05",
   "metadata": {},
   "source": [
    "# Data Analysis, Clinic 1\n",
    "# FIETS: Fundamentele Innovatie En Technologie in Scholing\n",
    "## Met FIETS blijft het onderwijs vooruitgaan, zelfs tegen de wind in!\n",
    "\n",
    "---\n",
    "\n",
    "By completing and delivering the clinic tasks you will know how to :\n",
    "\n",
    "- Load data and handle data using pandas;\n",
    "- Navigate the documentation of Python packages by yourself;\n",
    "- Filter and tidy up **noisy** real-world datasets;\n",
    "- Aggregate your data in different (and hopefully helpful) ways;\n",
    "- Use EDA to learn more about your data\n",
    "- Create and interpret informative visualizations to explore the data set\n",
    "- Derive meaningful insights for the societal impact of datasets\n",
    "\n",
    "---\n",
    "**Important Dates.**\n",
    "\n",
    "- Clinic 1 release: Thu 29 Jan 2026\n",
    "- Clinic 1 due: Mon 02 Feb 2026 late night, wildcards available\n",
    "\n",
    "**Instructions for the deliverable: notebook and poster**\n",
    "\n",
    "- You are allowed to use any built-in Python library that comes with Anaconda.  \n",
    "  If you want to use an external library, you may do so, but you must justify your choice.\n",
    "\n",
    "- Make sure that you include a proper balance of **comments, results, and code**.  \n",
    "  Provide a concise textual description of:\n",
    "  - your thought process,\n",
    "  - the assumptions you made,\n",
    "  - the solution you implemented,\n",
    "  - and explanations for your answers.  \n",
    "  A notebook that only contains code cells will not suffice.  \n",
    "  To avoid confusion: use short comments for longer code answers, and markdown cells for explanations.\n",
    "\n",
    "- For questions containing the **/Discuss:/** prefix, answer **with a textual explanation in markdown**, not with code.\n",
    "\n",
    "- Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "\n",
    "- Please write all comments in **English**, and use meaningful variable names in your code where possible.\n",
    "\n",
    "- Make sure that **all cells are executed properly** and that everything you need to show is visible in your executed notebook.  \n",
    "  We will **not** run your notebook for you.\n",
    "\n",
    "- In continuation to the previous point, **interactive plots** (e.g. those generated using `plotly`) are strictly avoided.  \n",
    "  Make sure to print results and/or dataframes that confirm you have properly addressed each task.\n",
    "\n",
    "- You are asked to deliver **two files only**:\n",
    "  - your executed notebook file (`.ipynb`), and\n",
    "  - your poster (`.pdf`).  \n",
    "  No other files will be graded.\n",
    "\n",
    "- **Poster requirement (‚ÄúBack-Propaganda‚Äù, see Task 4):**\n",
    "  - The poster must be a **single-page PDF**, created using the techniques discussed in class (e.g. clear visual hierarchy, minimal text, strong framing).\n",
    "  - The poster should summarize and frame key findings from **Tasks 1‚Äì3** (e.g. model accuracy, instability, answer-position bias, tokenization effects, cost/speed trade-offs).\n",
    "  - The poster must be delivered as a **single-page PDF**, in either portrait or landscape orientation.\n",
    "- **Poster assessment criteria:**\n",
    "  - Clarity of Message: Is the main takeaway immediately understandable? Are the conclusions framed clearly and correctly?\n",
    "  - Visual Design & Communication: Effective use of layout, color and visual hierarchy, appropriate choice of plots and figures (no clutter, readable labels)\n",
    "  - Connection to Data Analysis: Are the claims grounded in findings from **Tasks 1‚Äì3**? Does the poster accurately reflect the results without exaggeration or misrepresentation?\n",
    "  - Critical Perspective: Does the poster go beyond a simplistic ‚ÄúLMs are good / LMs are bad‚Äù narrative? Are limitations, risks, or uncertainties clearly acknowledged?\n",
    "  - Relevance to Education & Policy: Does the poster clearly relate to the **FIETS** context? Are implications for education, governance, and decision-makers made explicit?\n",
    "\n",
    "- **Honor code** applies to these tasks.  \n",
    "  If you are not certain about an action, consult with Jerry.\n",
    "\n",
    "\n",
    "**A Note from Jerry on using Language Models (LMs)**\n",
    "\n",
    "If you try hard enough, you will likely get away with cheating (that does not only apply to LMs). Fortunately, my job is not to police, but rather to educate you. So, please consider the following:\n",
    "\n",
    "I assume that you are taking this course to learn something! LMs are not always right ([they often fail in silly ways](https://community.openai.com/t/why-9-11-is-larger-than-9-9-incredible/869824/4)). This course should prepare you to detect when they are wrong!\n",
    "\n",
    "I don't restrict the use of LMs because I see the value of being helped when coding (esp. in the context of pandas dataframes nightmare :)). Based on what we saw last year in your notebooks, it's pretty clear when you \"copy\" some code and then you struggle to interpret the results. This is the essence of this course and of the skills you should try build for yourself: Many people can run fancy models these days but not many people can interpret the results correctly. Try to be the latter ones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136111e1",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "AI is booming! Newspapers, influencers and your relatives all agree that AI is important. But while almost everyone agrees that AI is the future, much is unclear about what that future esp. in critical sectors like education looks like...\n",
    "\n",
    "Freshly graduated from a top Dutch university in Limburg, you are hired by the Dutch government to advise on a large-scale ‚Äúeducation innovation‚Äù initiative code-named \"FIETS\" (Flexibele Innovatie voor Effici√´nte Toepassing in Scholing). With higher education facing severe budget cuts, the government is looking for creative solutions to \"do more with less.\" Convinced by the stunning progress in language modeling, officials believe LLMs could help battle growing teacher shortages and reduce costs by automating parts of the education process. Your job description: investigate which LMs might be best suited to plug the gaps without draining the budget!\n",
    "\n",
    "You are handed the results of three LMs on the [‚ÄúMassive Multitask Language Understanding (MMLU)‚Äù](https://arxiv.org/abs/2009.03300) dataset  to compare. This famous dataset consists of 57 subjects with multiple-choice questions, covering diverse subjects like mathematics, computer science, history, and law. Most providers of state-of-the-art LMs use this dataset to showcase the versatility of their latest models. Unfortunately, the intern responsible for collecting the results, didn‚Äôt pay attention during DACS KEN3450: Data Analysis. As a result, the collected datasets are slightly corrupted. Jammer!\n",
    "\n",
    "The success of FIETS depends on your ability to make sense of the messy data and recommend the best model to keep the Dutch education system pedaling forward‚Äîdespite uphill challenges like funding shortages and a skeptical academic community!\n",
    "\n",
    "### A very brief primer on Language Models\n",
    "We studied LLMs in the context of the NLP course but here is a short reminder. Language models (LMs) are sophisticated statistical models designed to understand and generate human-like text. At their core, LMs are trained to predict the most likely continuation of a given input text. For example, given the input \"The cat sat on the,\" an LM might predict \"mat\" as a likely continuation.\n",
    "LMs are trained on vast text samples from various sources, including books, websites, and social media. This extensive training allows them to capture patterns and relationships in language, enabling them to generate coherent and contextually appropriate text across a wide range of topics and styles.\n",
    "\n",
    "While LMs can produce text that appears to be written by intelligent humans, it's important to note that their capabilities can diverge from human intelligence in unexpected ways. They may sometimes generate factually incorrect information or struggle with complex reasoning tasks.\n",
    "\n",
    "Two key concepts in understanding LMs are:\n",
    "1. **Tokens**: LMs process text using \"tokens\" rather than individual characters. Tokens can be words, parts of words, or punctuation marks. For example, the sentence \"I love AI!\" might be tokenized as [\"I\", \"love\", \"AI\", \"!\"]. Tokenization is the first step in both training and using an LM.\n",
    "2. **Context**: The input text provided to an LM is called the \"context.\" This context informs the model's predictions or generations. A longer or more specific context often leads to more accurate and relevant outputs.\n",
    "\n",
    "[See: Wikipedia entry on language models](https://en.wikipedia.org/wiki/Large_language_model)\n",
    "\n",
    "###  Files for this assignment\n",
    "This assignment is divided into three tasks, each of which should bring you a step closer to providing a recommendation toward project the objectives of FIETS:\n",
    "\n",
    "- **Task 1**: Inspecting the results and getting your first model ranking\n",
    "- **Task 2**: Inspecting the underlying data used to generate the results for possible biases\n",
    "- **Task 3**: Learning about tokens and providing a final recommendation\n",
    "\n",
    "\n",
    "```\n",
    "üìÅ FIETS\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ üìÑ clinic1.ipynb (the file you're currently reading!)\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ üìÅ data\n",
    "    ‚îú‚îÄ‚îÄ üìÅ task_1\n",
    "    ‚îú‚îÄ‚îÄ üìÅ task_2\n",
    "    ‚îî‚îÄ‚îÄ üìÅ task_2.5\n",
    "```   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474f88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd19621",
   "metadata": {},
   "source": [
    "## Task 1 (18 points): What's in an average anyway?\n",
    "\n",
    "The files needed to complete task 1 can be found in the folder \"`data/task_1/`:\n",
    "```\n",
    "task_1/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ mmlu_data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test.csv\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores/\n",
    "    ‚îú‚îÄ‚îÄ lm_X.csv\n",
    "    ‚îú‚îÄ‚îÄ lm_Y.csv\n",
    "    ‚îî‚îÄ‚îÄ lm_Z.csv\n",
    "```\n",
    "\n",
    "We will start by loading, (manually) inspecting, and cleaning the data. Although it doesn't seem \"glamorous\" (nor is it particularly fun...) - manually inspecting data is extremely important! In fact, it's one of the few things most AI and Data Science researchers agree on :). Next, we will take a first pass on ordering our Olympic podium between three LMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b373e5",
   "metadata": {},
   "source": [
    "### 1.1 (1 pt)\n",
    " \n",
    "Load the subfiles contained in the `mmlu_data` and `lm_scores` folders into separate dataframes:\n",
    "- `df_test`\n",
    "- `df_x`\n",
    "- `df_y`\n",
    "- `df_z`\n",
    "\n",
    "for each, print their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc147f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test:  (14042, 8)\n",
      "df_x:  (13882, 2)\n",
      "df_y:  (13978, 2)\n",
      "df_z:  (13923, 2)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/task_1/mmlu_data/test.csv')\n",
    "\n",
    "f = 'data/task_1/lm_scores/'\n",
    "df_x = pd.read_csv(os.path.join(f, 'lm_X.csv'))\n",
    "df_y = pd.read_csv(os.path.join(f, 'lm_Y.csv'))\n",
    "df_z = pd.read_csv(os.path.join(f, 'lm_Z.csv'))\n",
    "\n",
    "print('df_test: ', df_test.shape)\n",
    "print('df_x: ', df_x.shape)\n",
    "print('df_y: ', df_y.shape)\n",
    "print('df_z: ', df_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c092787e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find the product of the given polynomials in t...</td>\n",
       "      <td>2x^2 + 5</td>\n",
       "      <td>6x^2 + 4x + 6</td>\n",
       "      <td>0</td>\n",
       "      <td>x^2 + 1</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>What has been a central focus of religious tra...</td>\n",
       "      <td>Peace and harmony</td>\n",
       "      <td>Power and influence</td>\n",
       "      <td>Truth and love</td>\n",
       "      <td>Wisdom and ethics</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14038</th>\n",
       "      <td>To whom did ordinary folk appeal during a dro...</td>\n",
       "      <td>The Buddha</td>\n",
       "      <td>Laozi</td>\n",
       "      <td>The Queen Mother of the West</td>\n",
       "      <td>Confucius</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14039</th>\n",
       "      <td>The theological term homoousios means which o...</td>\n",
       "      <td>of a similar substance</td>\n",
       "      <td>of the same substance</td>\n",
       "      <td>of like substance</td>\n",
       "      <td>of human substance</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14040</th>\n",
       "      <td>According to the Japanese origin myth, who giv...</td>\n",
       "      <td>Es</td>\n",
       "      <td>Izanagi</td>\n",
       "      <td>Izanami</td>\n",
       "      <td>Kami</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14041</th>\n",
       "      <td>The numen of Augustus referred to which of th...</td>\n",
       "      <td>Divine power</td>\n",
       "      <td>Sexual virility</td>\n",
       "      <td>Military acumen</td>\n",
       "      <td>Philosophical intellect</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14042 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      Find the degree for the given field extension ...   \n",
       "1      Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2      Find all zeros in the indicated finite field o...   \n",
       "3      Statement 1 | A factor group of a non-Abelian ...   \n",
       "4      Find the product of the given polynomials in t...   \n",
       "...                                                  ...   \n",
       "14037  What has been a central focus of religious tra...   \n",
       "14038   To whom did ordinary folk appeal during a dro...   \n",
       "14039   The theological term homoousios means which o...   \n",
       "14040  According to the Japanese origin myth, who giv...   \n",
       "14041   The numen of Augustus referred to which of th...   \n",
       "\n",
       "                            A                      B  \\\n",
       "0                           0                      4   \n",
       "1                           8                      2   \n",
       "2                           0                      1   \n",
       "3                  True, True           False, False   \n",
       "4                    2x^2 + 5          6x^2 + 4x + 6   \n",
       "...                       ...                    ...   \n",
       "14037       Peace and harmony    Power and influence   \n",
       "14038              The Buddha                  Laozi   \n",
       "14039  of a similar substance  of the same substance   \n",
       "14040                      Es                Izanagi   \n",
       "14041            Divine power        Sexual virility   \n",
       "\n",
       "                                  C                        D answer  \\\n",
       "0                                 2                        6      B   \n",
       "1                                24                      120      C   \n",
       "2                               0,1                      0,4      D   \n",
       "3                       True, False              False, True      B   \n",
       "4                                 0                  x^2 + 1      B   \n",
       "...                             ...                      ...    ...   \n",
       "14037                Truth and love        Wisdom and ethics      A   \n",
       "14038  The Queen Mother of the West                Confucius      C   \n",
       "14039             of like substance       of human substance      B   \n",
       "14040                       Izanami                     Kami      B   \n",
       "14041               Military acumen  Philosophical intellect      A   \n",
       "\n",
       "                subject  question_id  \n",
       "0      abstract algebra            0  \n",
       "1      abstract algebra            1  \n",
       "2      abstract algebra            2  \n",
       "3      abstract algebra            3  \n",
       "4      abstract algebra            4  \n",
       "...                 ...          ...  \n",
       "14037   world religions        14037  \n",
       "14038   world religions        14038  \n",
       "14039   world religions        14039  \n",
       "14040   world religions        14040  \n",
       "14041   world religions        14041  \n",
       "\n",
       "[14042 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5fd6b",
   "metadata": {},
   "source": [
    "### 1.2 (4 pt)\n",
    "Unfortunately, LMs don't always output the format we want. In the column `result`, the value should be one of A, B, C, or D. \n",
    "\n",
    "A. For each of the LM score dataframes, use a `value_counts()` operation and print the results. \n",
    "\n",
    "B. /Discuss:/ Inspect the results and describe the types of answer formats you see. Besides the \"expected\" case, you should be able to find at least four unexpected formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59b24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26adbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d89d5d",
   "metadata": {},
   "source": [
    "### 1.3 (5 pt)\n",
    "Oh oh... That doesn't look great. Simply dropping all invalid answers seems overly wasteful, yet fixing all of these looks like a mess! Instead, let's focus for now on fixing just those answers of length < 10 characters that require only a single `str.replace()` operation. \n",
    "\n",
    "For example, if the answer looks like `--A--`, we could fix this by using the following simple function:\n",
    "\n",
    "```\n",
    "def clean_answer(s, pattern='-'):\n",
    "    return str(s).replace(pattern, '')\n",
    "\n",
    "dirty_answer = '--A--'\n",
    "clean_answer = clean_answer(dirty_answer)\n",
    "```\n",
    "\n",
    "A. Filter the three score dataframes to include only answers with less than 10 characters. Make a deep copy of the dataframes as you filter them.\n",
    "\n",
    "B. Modify the `clean_answer()` example function to clean the answers in the filtered data frames using the `apply()` functionality. Finally, make sure **all remaining answers are one of `A, B, C, or D`.**\n",
    "\n",
    "C. /Discuss:/ Compare the sizes of the original and filtered data frames. What do you see? Why might this be a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227cf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8652bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025f0c9",
   "metadata": {},
   "source": [
    "C. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96891144",
   "metadata": {},
   "source": [
    "### 1.4 (3 pt)\n",
    "\n",
    "Now that our answer columns are nicely formatted, let's take a look at model performance:\n",
    "\n",
    "A. Both the `MMLU` dataframes and the language model score data frames have the columns `question_id`. For each of the language model score data frames, use an inner join operation with the `df_test` dataframe on the `question_id` column.\n",
    "\n",
    "B. Add a new column to each of the resulting dataframes called `correct`, that checks if the model's answer in `result` is the same as the expected answer in the column `answer`. Then, print the average score of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d3a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  0.767\n",
      "Y:  0.746\n",
      "Z:  0.663\n"
     ]
    }
   ],
   "source": [
    "# A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4662b",
   "metadata": {},
   "source": [
    "### 1.5 (5 pt)\n",
    "\n",
    "Hmmm, something doesn't seem quite right. Let's investigate how \"balanced\" this dataset is:\n",
    "\n",
    "A. For each of the 57 subjects in the MMLU, compare the number of questions answered by each model. Print the subjects for which there is a more than 10% difference.\n",
    "\n",
    "B. Propose and implement a reasonable way to rebalance the results. (e.g., while throwing away 100% of the results perfectly rebalances the results, it is not reasonable).\n",
    "\n",
    "C. Finally, print the updated accuracy on the rebalanced data.\n",
    "\n",
    "**hint:**:\n",
    "- (A) For a given subject, let model X and model Y have answered 181 and 200 questions respectively. You can consider this a 10% difference from the perspective of X, i.e., (200 - 181) / 181 > 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb79447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c6fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aea7ad",
   "metadata": {},
   "source": [
    "## Task 2 (26 points): What do you mean A > D > B > C...?\n",
    "\n",
    "Nice work! Having successfully inspected, cleaned, and rebalanced the provided data, you head over to director of the government's FIETS project operating under the code name Geronimo. He is happy with your work so far, but worried that the sloppy intern might have done more undetected damage. To be sure, he orders a new set of evaluations of all models on both MMLU and another dataset.\n",
    "\n",
    "After cleaning up and rebalancing, you are left with the concatenated score files in the second folder `task_2`:\n",
    "```\n",
    "task_2/\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores_mmlu.csv\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores_other.csv\n",
    "```\n",
    "\n",
    "Each has a new column called `model_name`, which is one of `X, Y` or `Z`.\n",
    "\n",
    "\n",
    "\n",
    "_NOTE: **only** use data from `task_2` and `task_2_5` for this assignment! The values in `lm_scores_mmlu.csv` will NOT be the same as the dataframes you finished in task 1. This is due to \"randomness\" or \"temperature\" in language model inference. This can slightly shift around generative results. (Conveniently: it also ensures any mistakes made in Task 1 don't propogate further ;) )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7caca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDED CODE\n",
    "df_mmlu = pd.read_csv('data/task_2/lm_scores_mmlu.csv')\n",
    "df_other = pd.read_csv('data/task_2/lm_scores_other.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a0e46",
   "metadata": {},
   "source": [
    "### 2.1 (4 pt)\n",
    "\n",
    "Let's explore the new results:\n",
    "\n",
    "A. Compute the mean accuracy and standard errors of each model on both datasets and print the results.\n",
    "\n",
    "*Hint: For the standard errors just use the .agg function option (check [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#dataframegroupby-computations-descriptive-stats))*\n",
    "\n",
    "B. Then, show your results in a bar plot using standard errors with a 95% confidence interval around the mean. Make sure the plot is easy to read and well annotated.\n",
    "\n",
    "*Hint: For the plots with the standard errors, depending on the method you use, you might have to plot the error bars manually on the plot. In that case, the standard error is 1.96 * se (where se is the values you computed in A)*\n",
    "\n",
    "C. /Discuss:/ the plot you created: (i) can you say that one of the models is the best? (ii) is there anything that seems odd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04c5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>correct</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>Statement 1 | A ring homomorphism is one to on...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35083</th>\n",
       "      <td>A</td>\n",
       "      <td>14037</td>\n",
       "      <td>What has been a central focus of religious tra...</td>\n",
       "      <td>Peace and harmony</td>\n",
       "      <td>Power and influence</td>\n",
       "      <td>Truth and love</td>\n",
       "      <td>Wisdom and ethics</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35084</th>\n",
       "      <td>C</td>\n",
       "      <td>14038</td>\n",
       "      <td>To whom did ordinary folk appeal during a dro...</td>\n",
       "      <td>The Buddha</td>\n",
       "      <td>Laozi</td>\n",
       "      <td>The Queen Mother of the West</td>\n",
       "      <td>Confucius</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35085</th>\n",
       "      <td>B</td>\n",
       "      <td>14039</td>\n",
       "      <td>The theological term homoousios means which o...</td>\n",
       "      <td>of a similar substance</td>\n",
       "      <td>of the same substance</td>\n",
       "      <td>of like substance</td>\n",
       "      <td>of human substance</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35086</th>\n",
       "      <td>B</td>\n",
       "      <td>14040</td>\n",
       "      <td>According to the Japanese origin myth, who giv...</td>\n",
       "      <td>Es</td>\n",
       "      <td>Izanagi</td>\n",
       "      <td>Izanami</td>\n",
       "      <td>Kami</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35087</th>\n",
       "      <td>A</td>\n",
       "      <td>14041</td>\n",
       "      <td>The numen of Augustus referred to which of th...</td>\n",
       "      <td>Divine power</td>\n",
       "      <td>Sexual virility</td>\n",
       "      <td>Military acumen</td>\n",
       "      <td>Philosophical intellect</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35088 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  question_id                                           question  \\\n",
       "0          B            0  Find the degree for the given field extension ...   \n",
       "1          C            1  Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2          D            2  Find all zeros in the indicated finite field o...   \n",
       "3          B            3  Statement 1 | A factor group of a non-Abelian ...   \n",
       "4          D            7  Statement 1 | A ring homomorphism is one to on...   \n",
       "...      ...          ...                                                ...   \n",
       "35083      A        14037  What has been a central focus of religious tra...   \n",
       "35084      C        14038   To whom did ordinary folk appeal during a dro...   \n",
       "35085      B        14039   The theological term homoousios means which o...   \n",
       "35086      B        14040  According to the Japanese origin myth, who giv...   \n",
       "35087      A        14041   The numen of Augustus referred to which of th...   \n",
       "\n",
       "                            A                      B  \\\n",
       "0                           0                      4   \n",
       "1                           8                      2   \n",
       "2                           0                      1   \n",
       "3                  True, True           False, False   \n",
       "4                  True, True           False, False   \n",
       "...                       ...                    ...   \n",
       "35083       Peace and harmony    Power and influence   \n",
       "35084              The Buddha                  Laozi   \n",
       "35085  of a similar substance  of the same substance   \n",
       "35086                      Es                Izanagi   \n",
       "35087            Divine power        Sexual virility   \n",
       "\n",
       "                                  C                        D answer  \\\n",
       "0                                 2                        6      B   \n",
       "1                                24                      120      C   \n",
       "2                               0,1                      0,4      D   \n",
       "3                       True, False              False, True      B   \n",
       "4                       True, False              False, True      D   \n",
       "...                             ...                      ...    ...   \n",
       "35083                Truth and love        Wisdom and ethics      A   \n",
       "35084  The Queen Mother of the West                Confucius      C   \n",
       "35085             of like substance       of human substance      B   \n",
       "35086                       Izanami                     Kami      B   \n",
       "35087               Military acumen  Philosophical intellect      A   \n",
       "\n",
       "                subject  correct model_name  \n",
       "0      abstract algebra     True          X  \n",
       "1      abstract algebra     True          X  \n",
       "2      abstract algebra     True          X  \n",
       "3      abstract algebra     True          X  \n",
       "4      abstract algebra     True          X  \n",
       "...                 ...      ...        ...  \n",
       "35083   world religions     True          Z  \n",
       "35084   world religions     True          Z  \n",
       "35085   world religions     True          Z  \n",
       "35086   world religions     True          Z  \n",
       "35087   world religions     True          Z  \n",
       "\n",
       "[35088 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c272f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>Which factor will most likely cause a person t...</td>\n",
       "      <td>a leg muscle relaxing after exercise</td>\n",
       "      <td>a bacterial population in the bloodstream</td>\n",
       "      <td>several viral particles on the skin</td>\n",
       "      <td>carbohydrates being digested in the stomach</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>Lichens are symbiotic organisms made of green ...</td>\n",
       "      <td>carbon dioxide</td>\n",
       "      <td>food</td>\n",
       "      <td>protection</td>\n",
       "      <td>water</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>When a switch is used in an electrical circuit...</td>\n",
       "      <td>cause the charge to build.</td>\n",
       "      <td>increase and decrease the voltage.</td>\n",
       "      <td>cause the current to change direction.</td>\n",
       "      <td>stop and start the flow of current.</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>Which of the following is an example of an ass...</td>\n",
       "      <td>contact lens</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>raincoat</td>\n",
       "      <td>coffee pot</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>Rocks are classified as igneous, metamorphic, ...</td>\n",
       "      <td>their color</td>\n",
       "      <td>their shape</td>\n",
       "      <td>how they formed</td>\n",
       "      <td>the minerals they contain</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>B</td>\n",
       "      <td>4479</td>\n",
       "      <td>Iron oxides, such as rust, form when iron meta...</td>\n",
       "      <td>I and O</td>\n",
       "      <td>Ir and O</td>\n",
       "      <td>Fe and O</td>\n",
       "      <td>Pb and O</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11273</th>\n",
       "      <td>A</td>\n",
       "      <td>4480</td>\n",
       "      <td>When water evaporates from Earth's surface int...</td>\n",
       "      <td>The mass is reduced.</td>\n",
       "      <td>The volume is increased.</td>\n",
       "      <td>The temperature is reduced.</td>\n",
       "      <td>The pressure is increased.</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11274</th>\n",
       "      <td>C</td>\n",
       "      <td>4481</td>\n",
       "      <td>Which process directly adds carbon into the at...</td>\n",
       "      <td>increasing plant populations</td>\n",
       "      <td>decreasing animal populations</td>\n",
       "      <td>burning fossil fuels</td>\n",
       "      <td>forming sedimentary rock</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>D</td>\n",
       "      <td>4482</td>\n",
       "      <td>Scientists think that dolphins and whales may ...</td>\n",
       "      <td>They swim the same way.</td>\n",
       "      <td>They eat the same food.</td>\n",
       "      <td>They live in the same area of the ocean.</td>\n",
       "      <td>They have similar anatomies.</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>D</td>\n",
       "      <td>4483</td>\n",
       "      <td>A particular organism is able to survive in an...</td>\n",
       "      <td>swimming in arctic waters</td>\n",
       "      <td>eating large amounts of fish</td>\n",
       "      <td>being preyed upon by other animals</td>\n",
       "      <td>living in an environment with high temperatures</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11277 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  question_id                                           question  \\\n",
       "0          B            0  Which factor will most likely cause a person t...   \n",
       "1          B            1  Lichens are symbiotic organisms made of green ...   \n",
       "2          D            2  When a switch is used in an electrical circuit...   \n",
       "3          A            3  Which of the following is an example of an ass...   \n",
       "4          C            4  Rocks are classified as igneous, metamorphic, ...   \n",
       "...      ...          ...                                                ...   \n",
       "11272      B         4479  Iron oxides, such as rust, form when iron meta...   \n",
       "11273      A         4480  When water evaporates from Earth's surface int...   \n",
       "11274      C         4481  Which process directly adds carbon into the at...   \n",
       "11275      D         4482  Scientists think that dolphins and whales may ...   \n",
       "11276      D         4483  A particular organism is able to survive in an...   \n",
       "\n",
       "                                          A  \\\n",
       "0      a leg muscle relaxing after exercise   \n",
       "1                            carbon dioxide   \n",
       "2                cause the charge to build.   \n",
       "3                              contact lens   \n",
       "4                               their color   \n",
       "...                                     ...   \n",
       "11272                               I and O   \n",
       "11273                  The mass is reduced.   \n",
       "11274          increasing plant populations   \n",
       "11275               They swim the same way.   \n",
       "11276             swimming in arctic waters   \n",
       "\n",
       "                                               B  \\\n",
       "0      a bacterial population in the bloodstream   \n",
       "1                                           food   \n",
       "2             increase and decrease the voltage.   \n",
       "3                                     motorcycle   \n",
       "4                                    their shape   \n",
       "...                                          ...   \n",
       "11272                                   Ir and O   \n",
       "11273                   The volume is increased.   \n",
       "11274              decreasing animal populations   \n",
       "11275                    They eat the same food.   \n",
       "11276               eating large amounts of fish   \n",
       "\n",
       "                                              C  \\\n",
       "0           several viral particles on the skin   \n",
       "1                                    protection   \n",
       "2        cause the current to change direction.   \n",
       "3                                      raincoat   \n",
       "4                               how they formed   \n",
       "...                                         ...   \n",
       "11272                                  Fe and O   \n",
       "11273               The temperature is reduced.   \n",
       "11274                      burning fossil fuels   \n",
       "11275  They live in the same area of the ocean.   \n",
       "11276        being preyed upon by other animals   \n",
       "\n",
       "                                                     D answer  correct  \\\n",
       "0          carbohydrates being digested in the stomach      B     True   \n",
       "1                                                water      B     True   \n",
       "2                  stop and start the flow of current.      D     True   \n",
       "3                                           coffee pot      A     True   \n",
       "4                            the minerals they contain      C     True   \n",
       "...                                                ...    ...      ...   \n",
       "11272                                         Pb and O      C    False   \n",
       "11273                       The pressure is increased.      C    False   \n",
       "11274                         forming sedimentary rock      C     True   \n",
       "11275                     They have similar anatomies.      D     True   \n",
       "11276  living in an environment with high temperatures      A    False   \n",
       "\n",
       "      model_name  \n",
       "0              X  \n",
       "1              X  \n",
       "2              X  \n",
       "3              X  \n",
       "4              X  \n",
       "...          ...  \n",
       "11272          Z  \n",
       "11273          Z  \n",
       "11274          Z  \n",
       "11275          Z  \n",
       "11276          Z  \n",
       "\n",
       "[11277 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9020bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mmlu stats:\n",
      "                mean       sem\n",
      "model_name                    \n",
      "X           0.743588  0.004038\n",
      "Y           0.761542  0.003941\n",
      "Z           0.655951  0.004393\n",
      "\n",
      "df_other stats:\n",
      "                mean       sem\n",
      "model_name                    \n",
      "X           0.787976  0.006668\n",
      "Y           0.720936  0.007317\n",
      "Z           0.671721  0.007660\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "# To calculate mean accuracy we look at the 'correct' column which indicates if the model's answer was True (1) or False (0) and average these values for each model.\n",
    "# So it is basically the proportion of correct answers given by each model.\n",
    "stats_mmlu = df_mmlu.groupby('model_name')['correct'].agg(['mean', 'sem'])\n",
    "stats_other = df_other.groupby('model_name')['correct'].agg(['mean', 'sem'])\n",
    "\n",
    "print(\"df_mmlu stats:\")\n",
    "print(stats_mmlu)\n",
    "print(\"\\ndf_other stats:\")\n",
    "print(stats_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fc22d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#B\n",
    "summary = pd.DataFrame({\n",
    "    'MMLU': stats_mmlu['mean'],\n",
    "    'Other': stats_other['mean']\n",
    "})\n",
    "\n",
    "errors = pd.DataFrame({\n",
    "    'MMLU': stats_mmlu['sem'] * 1.96,\n",
    "    'Other': stats_other['sem'] * 1.96\n",
    "})\n",
    "\n",
    "summary.plot(kind='bar', yerr=errors, capsize=5, rot=0)\n",
    "\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.title(\"Model performance on MMLU and Other Datasets\")\n",
    "plt.legend(title=\"Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361519b",
   "metadata": {},
   "source": [
    "C. \n",
    "(i) It's hard to say if one model is the best because they have different results on the different datasets. We can see that in df_mmlu model Y has the best mean accuracy, while in df_other it is model X who does. The only consistency is that in both datasets model Z has the worst performance.\n",
    "(ii) It is a bit odd that models X and Y have have quite different results on the different datasets. The datasets might be different in a way that impacts the result of these models. Another thing I noticed was that the standard errors of all models in the other dataset are much bigger than in mmlu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e1367",
   "metadata": {},
   "source": [
    "### 2.2 (5 pt)\n",
    "\n",
    "Geronimo has assured you that both datasets contain questions of similar difficulty, so, what could be going on here?\n",
    "\n",
    "A. What is the distribution of correct answers (A, B, C, D) for each dataset? Create a bar chart to visualize this.\n",
    "\n",
    "B. Perform a chi-square test at $\\alpha = 0.05$, of independence to determine if there's a significant difference in the distribution of correct answers between the two datasets. What do you conclude?\n",
    "\n",
    "**hints**:\n",
    "- for (A), keep in mind that df_mmlu and df_other contain the results of all models, i.e., the `question_id` column is duplicated.\n",
    "- for (A), take care to clearly annotate the bar chart, e.g., title, y-label, legend.\n",
    "- for (B), clearly state the null hypothesis and alternative hypothesis\n",
    "- use the `chi2_contingency` function from `scipy.stats`\n",
    "- format your results from answer (A) as a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46d14e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A \n",
    "df_mmlu_unique = df_mmlu.drop_duplicates(subset=['question_id'])\n",
    "df_other_unique = df_other.drop_duplicates(subset=['question_id'])\n",
    "\n",
    "counts_mmlu = df_mmlu_unique['answer'].value_counts().sort_index()\n",
    "counts_other = df_other_unique['answer'].value_counts().sort_index()\n",
    "\n",
    "counts_df = pd.DataFrame({\n",
    "    'MMLU': counts_mmlu,    \n",
    "    'Other': counts_other\n",
    "})\n",
    "\n",
    "counts_df.plot(kind='bar')\n",
    "\n",
    "plt.xlabel(\"Answer Key\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of answer keys\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b9a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared test p-value: \n",
      "4.270849602795191e-136\n"
     ]
    }
   ],
   "source": [
    "#B\n",
    "#H0: The distribution of answer keys is the same for MMLU and Other datasets.\n",
    "#H1: The distribution of answer keys is different for MMLU and Other datasets.\n",
    "counts_df.T\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(counts_df.T)\n",
    "print(\"Chi-squared test p-value: \")\n",
    "print(p)\n",
    "\n",
    "# The p-value is much smaller than 0.05, so we reject the null hypothesis. \n",
    "# This means that the distribution of answer keys is completely different for MMLU and Other datasets, which was already visible in the bar plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8b7eb",
   "metadata": {},
   "source": [
    "### 2.3 (7 pt)\n",
    "\n",
    "Let's dive in deeper:\n",
    "\n",
    "A. What is language model X's mean accuracy conditioned on the four answer options for each dataset?\n",
    "\n",
    "B. Compare LM X's performance when the correct answer is \"A\" between the two datasets. Use a T-test with CI = 0.95. What do you conclude?\n",
    "\n",
    "C. Compare LM X's performance when the correct answer is \"A\" vs. \"C or D\" for each dataset. Use a T-test with CI = 0.95. What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56c0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model X accuracy per answer (MMLU):\n",
      "answer\n",
      "A    0.972688\n",
      "B    0.799185\n",
      "C    0.707905\n",
      "D    0.633592\n",
      "Name: correct, dtype: float64\n",
      "\n",
      "Model X accuracy per answer (Other):\n",
      "answer\n",
      "A    0.974026\n",
      "B    0.806452\n",
      "C    0.676407\n",
      "D    0.603744\n",
      "Name: correct, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A\n",
    "\n",
    "df_mmlu_x = df_mmlu[df_mmlu['model_name'] == 'X']\n",
    "df_other_x = df_other[df_other['model_name'] == 'X']\n",
    "\n",
    "acc_mmlu_x = df_mmlu_x.groupby('answer')['correct'].mean()\n",
    "acc_other_x = df_other_x.groupby('answer')['correct'].mean()\n",
    "\n",
    "print(\"Model X accuracy per answer (MMLU):\")\n",
    "print(acc_mmlu_x)\n",
    "print(\"\\nModel X accuracy per answer (Other):\")\n",
    "print(acc_other_x)\n",
    "\n",
    "# The results look quite suspicious, A has much higher accuracy than the other letters in both datasets, specially compared to D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58da81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value comparing 'A' questions between datasets: 0.8332191972699248\n"
     ]
    }
   ],
   "source": [
    "#B\n",
    "# H0: There is no significant difference in Model X's accuracy on \"A\" questions between the two datasets\n",
    "# H1: There is a significant difference in Model X's accuracy on \"A\" questions between the two datasets\n",
    "group_mmlu_A = df_mmlu_x[df_mmlu_x['answer'] == 'A']['correct']\n",
    "group_other_A = df_other_x[df_other_x['answer'] == 'A']['correct']\n",
    "\n",
    "t_stat, p_val = ttest_ind(group_mmlu_A, group_other_A)\n",
    "\n",
    "print(f\"P-value comparing 'A' questions between datasets: {p_val}\")\n",
    "# Since p > 0.05, we fail to reject the null hypothesis. Model X performs equally well on \"A\" questions no matter the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e0ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU: P-value comparing 'A' vs 'C/D': 5.334906497224946e-139\n",
      "Other: P-value comparing 'A' vs 'C/D': 5.900859805611251e-96\n"
     ]
    }
   ],
   "source": [
    "#C\n",
    "# H0: There is no significant difference in Model X's accuracy on \"A\" questions vs \"C\" or \"D\" questions within each dataset.\n",
    "# H1: There is a significant difference in Model X's accuracy on \"A\" questions vs \"C\" or \"D\" questions within each dataset.\n",
    "group_mmlu_CD = df_mmlu_x[df_mmlu_x['answer'].isin(['C', 'D'])]['correct']\n",
    "\n",
    "t_stat_mmlu, p_val_mmlu = ttest_ind(group_mmlu_A, group_mmlu_CD)\n",
    "print(f\"MMLU: P-value comparing 'A' vs 'C/D': {p_val_mmlu}\")\n",
    "\n",
    "group_other_CD = df_other_x[df_other_x['answer'].isin(['C', 'D'])]['correct']\n",
    "\n",
    "t_stat_other, p_val_other = ttest_ind(group_other_A, group_other_CD)\n",
    "print(f\"Other: P-value comparing 'A' vs 'C/D': {p_val_other}\")\n",
    "# In both datasets, p < 0.05, so we reject the null hypothesis. Model X performs significantly better on \"A\" questions compared to \"C\" or \"D\" questions within each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd7b53",
   "metadata": {},
   "source": [
    "### 2.4 (2 pt)\n",
    "\n",
    "What an intriguing finding! \n",
    "\n",
    "A. Print the mean accuracies conditioned on the correct answer for all LMs for each dataset.\n",
    "\n",
    "B. /Discuss:/ What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77dc369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per answer key in mmlu dataset:\n",
      "model_name  answer\n",
      "X           A         0.972688\n",
      "            B         0.799185\n",
      "            C         0.707905\n",
      "            D         0.633592\n",
      "Y           A         0.623836\n",
      "            B         0.688073\n",
      "            C         0.733470\n",
      "            D         0.904252\n",
      "Z           A         0.643079\n",
      "            B         0.641182\n",
      "            C         0.669115\n",
      "            D         0.661139\n",
      "Name: correct, dtype: float64\n",
      "\n",
      "Accuracy per answer key in other dataset:\n",
      "model_name  answer\n",
      "X           A         0.974026\n",
      "            B         0.806452\n",
      "            C         0.676407\n",
      "            D         0.603744\n",
      "Y           A         0.625232\n",
      "            B         0.663978\n",
      "            C         0.762987\n",
      "            D         0.920437\n",
      "Z           A         0.680891\n",
      "            B         0.667563\n",
      "            C         0.662338\n",
      "            D         0.677067\n",
      "Name: correct, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#A\n",
    "print(\"Accuracy per answer key in mmlu dataset:\")\n",
    "print(df_mmlu.groupby(['model_name', 'answer'])['correct'].mean())\n",
    "\n",
    "print(\"\\nAccuracy per answer key in other dataset:\")\n",
    "print(df_other.groupby(['model_name', 'answer'])['correct'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973e6b5",
   "metadata": {},
   "source": [
    "B. From these results we can see that model Y is also biased on both datasets, this time having a much higher accuracy in questions where the answer is D, which constrasts with model X, that had much higher accuracy in answers A. On the other hand, the accuracy of model Z seems stable for all answers in both datasets. This behaviour in models X and Y could be the reason why we saw better results from them earlier compared to model Z. Model X might have performed better in the other dataset simply because that dataset had more A answers, and the other way around for model Y in the mmlu dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baea1ee",
   "metadata": {},
   "source": [
    "### 2.5 (2 pt)\n",
    "\n",
    "Concerned with your findings so far, you quickly consult with Geronimo. After thinking it over, Geronimo concludes that more tests are needed. He orders a second round of MMLU results. However, Geronimo thinks of the following twist: while keeping questions fixed, he randomly permutes the position of the correct answer. The new results can be found in the folder `data/task_2_5/`:\n",
    "```\n",
    "task_2_5/\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores_mmlu_shuffle.csv\n",
    "```\n",
    "\n",
    "/Discuss:/ Why would Geronimo do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411ddb7",
   "metadata": {},
   "source": [
    "B. Geronimo probably did this to see if the models actually know the answers or if they are just guessing their favorite letter. If the model fails after the shuffle, it shows it was relying on the letter position rather than actually understanding the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be659e2",
   "metadata": {},
   "source": [
    "### 2.6 (4 pt)\n",
    "\n",
    "Increasingly sceptical of the language models' performance, you read up on proper testing practices. You stumble upon the concept of [test-rested stability](https://en.wikipedia.org/wiki/Repeatability), which roughtly states that:\n",
    "\n",
    "\"_Measurements taken by a single person or instrument on the same item, under the same conditions, and in a short period of time, should have the same results._\"\n",
    "\n",
    "In our case, we would assume an LM would have the same performance on a given question regardless of the correct answer position. One way of testing this is by using the following metric:\n",
    "\n",
    "$$\\text{test-retest metric} = \\frac{1}{N}\\sum_{i=1}^N \\frac{1}{M}\\sum_{j=1}^M c^i_0 c_j^i,$$\n",
    "\n",
    "where $c^i_0 \\in \\{0, 1\\}$ indicates whether the model answers the $i^{\\text{th}}$ question correctly (1 if correct, 0 if incorrect). $c_j^i$ indicates whether the model answers the $i^{\\text{th}}$ question correctly in the $j^{\\text{th}}$ shuffled version of the answer label content. Finally, $M$ is the total number of shuffles and $N$ is the dataset size.\n",
    "\n",
    "Task: compute the test-retest metric for each language model using the original `lm_scores_mmlu.csv` file and the new `lm_scores_mmlu_shuffle.csv` file. Using a bar plot, visualize your results by comparing the accuracy of the original `lm_scores_mmlu.csv` and the test-retest scores.\n",
    "\n",
    "**hints**\n",
    "- what is $M$ in our case?\n",
    "\n",
    "(bonus: no points, but so much sweet, sweet knowledge - check out [the following article](https://arxiv.org/pdf/2406.19470v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy:\n",
      "model_name\n",
      "X    0.743588\n",
      "Y    0.761542\n",
      "Z    0.655951\n",
      "Name: correct_orig, dtype: float64\n",
      "\n",
      "Test-Retest stability:\n",
      "model_name\n",
      "X    0.588406\n",
      "Y    0.571648\n",
      "Z    0.441604\n",
      "Name: stable_correct, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M equals 1 in our case because we only have one shuffled version of the answer label content, which makes the formula much simpler\n",
    "\n",
    "df_shuffle = pd.read_csv('data/task_2_5/lm_scores_mmlu_shuffle.csv')\n",
    "merged = pd.merge(df_mmlu, df_shuffle, on=['question_id', 'model_name'], suffixes=('_orig', '_shuf'))\n",
    "\n",
    "merged['stable_correct'] = merged['correct_orig'] & merged['correct_shuf']\n",
    "test_retest_scores = merged.groupby('model_name')['stable_correct'].mean()\n",
    "original_scores = merged.groupby('model_name')['correct_orig'].mean()\n",
    "\n",
    "print(\"Original accuracy:\")\n",
    "print(original_scores)\n",
    "print(\"\\nTest-Retest stability:\")\n",
    "print(test_retest_scores)\n",
    "\n",
    "stability_data = pd.DataFrame({\n",
    "    'Original accuracy': original_scores,\n",
    "    'Test-Retest stability': test_retest_scores\n",
    "})\n",
    "\n",
    "stability_data.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "plt.title(\"Model robustness\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# For models X and Y here we see a significant drop in accuracy when the answer labels are shuffled, indicating that these models were relying on patterns in the answer labels to some extent.\n",
    "# Model Z's accuracy also had a big drop, which I did not expect, since it didn't show much bias when looking at the answer key distributions.\n",
    "# Its interesting also to notice that it's stability score is almost exactly the square of its original accuracy, which may indicate that the correctness of this model is independent between trials.\n",
    "# This model could be generating the answers probabilistically rather than actually knowing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5fb787",
   "metadata": {},
   "source": [
    "### 2.7 (2 pt)\n",
    "\n",
    "A. Using the unshuffled data: For each LM, print the distribution of the answers they give as well as the accuracy conditioned on the answer they give.\n",
    "\n",
    "B. /Discuss:/ Describe what you observe\n",
    "\n",
    "[bonus: not scored, but again _that sweet, sweet knowledge_] Could you think of a plausible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc52d5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction distribution per model:\n",
      "result             A         B         C         D\n",
      "model_name                                        \n",
      "X           0.364142  0.227343  0.205968  0.202548\n",
      "Y           0.091655  0.192886  0.257780  0.457678\n",
      "Z           0.186047  0.246666  0.276761  0.290527\n",
      "\n",
      "Accuracy per predicted answer:\n",
      "result             A         B         C         D\n",
      "model_name                                        \n",
      "X           0.367927  0.884543  1.000000  1.000000\n",
      "Y           0.937500  0.897606  0.827861  0.631608\n",
      "Z           0.476103  0.654073  0.703429  0.727487\n"
     ]
    }
   ],
   "source": [
    "#A\n",
    "print(\"Prediction distribution per model:\")\n",
    "dist = df_mmlu.groupby('model_name')['result'].value_counts(normalize=True).unstack().fillna(0)\n",
    "print(dist)\n",
    "\n",
    "print(\"\\nAccuracy per predicted answer:\")\n",
    "acc_pred = df_mmlu.groupby(['model_name', 'result'])['correct'].mean().unstack().fillna(0)\n",
    "print(acc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b2878",
   "metadata": {},
   "source": [
    "B. Observations and plausible explanations:\n",
    "Model X - Here we see that the model chooses A more often than the other letters. However, when it chooses A, it is only correct 37% of the time. This highlights a huge contrast between accuracy and precision. In question 2.4, we saw it had 97% accuracy on A questions, but that's just because it spams A even when the answer is actually B, C, or D. On the other hand, its precision on C and D is 100%. This suggests Model X is extremely conservative, it only picks C or D if it is absolutely certain. Otherwise, it defaults to guessing A.\n",
    "Model Y - This model shows the inverse behavior. It defaults to D nearly 46% of the time. While it catches most real Ds (High Recall), its precision when choosing \"D\" is around 63%, which is much lower.\n",
    "Model Z - This model has a much more balanced behaviour, its precision and recall are roughly aligned in all options, which shows that its the only model that is not relying on one letter answer as a default strategy.\n",
    "\n",
    "In general, the behaviour of models X and Y are uncalibrated. When they are unsure they collapse to a default letter (A or D) rather than guessing randomly, possibly due to biases in their training data (like more answers being A)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a1e11",
   "metadata": {},
   "source": [
    "## Task 3 (16 points): What do Questions and Answers look like for a Language Model?\n",
    "\n",
    "While you feel pretty good about the tests you conducted so far, something still bothers you: what if the language models don't see the data like you do? Suddenly, you receive a phone call from a wise AI sage based in Maastricht named Yodata:\n",
    "\n",
    "```\n",
    "\"Hmmm, correct you are, jonge padawan, to question how the wereld is seen by large language models! Simple 'text,' it is not, nee nee nee! Characters and words, the way of gewone humans, this is not, heh heh heh.\n",
    "\n",
    "'Tokens,' they use, ja! Mysterious and powerful, these tokens are. Expand our vocabulary, they do, beyond the simple 'a to Z.' Chunky blocks of text, they become, yes! 'Hello world,' a simple phrase it may seem. But to a language model, '[24912, 2375]' it might appear, hmm? Verwarrend, it is!\n",
    "\n",
    "Wise, it would be, to explore these MMLU data points through the eyes of a language model, you think? Yes, yes! Much to learn, there is. The ways of the tokens, understand you must, if truly comprehend the great LMs, you wish to.\n",
    "\n",
    "Meditate on this, you should. The force of natural language processing, strong it is. But geduld, you must have, my jonge padawan. For only through great study and contemplation, will the mysteries of the tokens reveal themselves to you, they will. Ja, hmmm!\"\n",
    "```\n",
    "\n",
    "Admittingly, Yodata at times speaks in riddles... However, he was explaining a crucial aspect of modern LMs called [Tokenization](https://learn.microsoft.com/en-us/dotnet/ai/conceptual/understanding-tokens):\n",
    "\n",
    "\n",
    "‚ÄúTokens are words, character sets, or combinations of words and punctuation that are used by [language models (LMs)] to decompose text into. Tokenization is the first step in training‚Äù\n",
    "\n",
    "Instead of characters, LMs process natural language using ‚Äútokens‚Äù. While this is useful for a number of reasons, it does at times introduce some ‚Äúunintuitive‚Äù behavior‚Ä¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e205d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humans see: \"hello world\" --> language models see: [24912, 2375]\n"
     ]
    }
   ],
   "source": [
    "# PROVIDED CODE\n",
    "\n",
    "try:\n",
    "    import tiktoken\n",
    "except Exception as e:\n",
    "    print('installing tiktoken package')\n",
    "    \n",
    "    !pip install tiktoken\n",
    "    \n",
    "    import tiktoken\n",
    "\n",
    "def tokenize_text(s):\n",
    "    enc = tiktoken.encoding_for_model('gpt-4o')\n",
    "    tokens = enc.encode(str(s))\n",
    "    return tokens\n",
    "\n",
    "example_string = 'hello world'\n",
    "print(f'humans see: \"{example_string}\" --> language models see: {tokenize_text(example_string)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cb7a5",
   "metadata": {},
   "source": [
    "### 3.1 (5 pt)\n",
    "\n",
    "Use the provided code in the cell above to \"see the world through the eyes of a language model\":\n",
    "\n",
    "A. Tokenize the questions of the original MMLU data provided in task 1: `task_1/mmlu_data/test.csv` and plot the token distribution (the frequency of each token).\n",
    "\n",
    "B. Same as (A), but now for the answers in columns (columns \"A\", \"B\", \"C\", and \"D\").\n",
    "\n",
    "C. Isolate the tokens for the strings \"A\", \"B\", \"C\", and \"D\", then, for their occurances in both questions and answers, print their relative distribution to each other.\n",
    "\n",
    "**hint**\n",
    "- There are a _lot_ of tokens, consider using a cutoff point and log scale\n",
    "- For (c), they should sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a83cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86208675",
   "metadata": {},
   "source": [
    "### 3.2 (3 pt)\n",
    "\n",
    "What if the number of \"A\", \"B\", \"C\", and \"D\" tokens in the question and answer pairs could influence a language model's decisions?\n",
    "\n",
    "A. For each question-answer pair, compute: \n",
    "1. the number of \"A\", \"B\", \"C\", and \"D\" tokens that occur in the combined question and answers; \n",
    "2. an the total number of tokens.\n",
    "3. then, group by the \"correct\" answer and compute the mean frequency of A, B, C, and D tokens and the total number of tokens. \n",
    "4. finally, print your results\n",
    "\n",
    "B. /Discuss:/ What do you think of the hypothesis that the frequency of A, B, C, and D tokens could influence answers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "196206e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.243017</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>93.187151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.231947</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>88.846332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.226410</td>\n",
       "      <td>0.018984</td>\n",
       "      <td>0.034897</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>92.653825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.242850</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>92.110169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A         B         C         D      total\n",
       "            mean      mean      mean      mean       mean\n",
       "answer                                                   \n",
       "A       0.243017  0.018932  0.025140  0.013035  93.187151\n",
       "B       0.231947  0.019642  0.029463  0.012709  88.846332\n",
       "C       0.226410  0.018984  0.034897  0.015355  92.653825\n",
       "D       0.242850  0.014566  0.030985  0.014301  92.110169"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b659fbc",
   "metadata": {},
   "source": [
    "B. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0066e5",
   "metadata": {},
   "source": [
    "### 3.3 (4 pt)\n",
    "\n",
    "Three of the most important considerations when deciding between language models are:\n",
    "\n",
    "Quality\n",
    "Costs\n",
    "Speed\n",
    "\n",
    "So far, much of your analysis has focused on quality. However, the government has indicated that they are quite concerned about both the total costs and speed as well. Specifically, it has been brought to their attention that a new `turbo` model has been launched! \n",
    "\n",
    "This model is both cheaper and faster than the models you evaluated so far. However, there is a catch: the context length* is much smaller than that of the other LMS. Namely, it can only process **300** tokens during inference. Meanwhile, the other models can process up to 100K tokens! \n",
    "\n",
    "*_The ‚Äúcontext length‚Äù refers to the number of tokens that can be given to an LM as input._\n",
    "\n",
    "A. Are there subjects where using the cheaper model might be problematic? I.e., where part of the question and answer(s) might not fit completely in the context?\n",
    "\n",
    "B. /Discuss:/ Can you think of a strategy that would balance the needs of the government?\n",
    "\n",
    "**hint**:\n",
    "- An LM needs to have both the question and the different answer options in its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3964ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1294d53",
   "metadata": {},
   "source": [
    "B. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a187c1",
   "metadata": {},
   "source": [
    "### 3.4 (4 pt)\n",
    "\n",
    "/Discuss:/ The time has come to give your final recommendation on the use of LMs in education to the government! Taking into account everything you analyzed in all the preceding tasks (1, 2, and 3), please write a short recommendation consisting of 4 bullet points discussing your concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c0a92",
   "metadata": {},
   "source": [
    "B. /Discuss:/\n",
    "\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941cdf1",
   "metadata": {},
   "source": [
    "## Task 4 (40 points): \"Back-Propaganda\" - Make a poster for FIETS \n",
    "\n",
    "/Design a visual poster (use the techniques we discussed in class) to frame some of your findings about LLMs. The poster should visually communicate the main insights and concerns that emerged from the analysis of language models in the FIETS project. Its goal is not to overwhelm with technical detail, but to clearly frame key findings for a broad, non-technical audience, such as policymakers, educators or the general public.\n",
    "\n",
    "A strong poster could include (but please don't feel limited by these): (a) the role of LMs in education, (b) \"performance is not neutral\": how does model accuracy depend on external factors (c) Reliability and robustness concerns, (d) Practical constraints and trade-offs, (e) Societal and policy implications\n",
    "\n",
    "The poster should rely on clear visuals (simple bar plots, schematic diagrams, icons, short captions, etc.) and very limited text, guiding the reader to the main takeaway in a few seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e469a21",
   "metadata": {},
   "source": [
    "Assessment Criteria:\n",
    "\n",
    "++ Clarity of Message\n",
    "- Is the main takeaway immediately understandable?\n",
    "- Are the conclusions framed clearly and correctly?\n",
    "\n",
    "++ Visual Design & Communication\n",
    "- Effective use of layout, color, and visual hierarchy\n",
    "- Appropriate choice of plots/figures (no clutter, readable labels)\n",
    "\n",
    "++ Connection to Data Analysis\n",
    "- Are the claims grounded in findings from Tasks 1‚Äì3?\n",
    "- Does the poster accurately reflect the results without exaggeration?\n",
    "\n",
    "++ Critical Perspective\n",
    "- Does the poster go beyond ‚ÄúLMs are good/bad‚Äù?\n",
    "- Are limitations, risks, or uncertainties clearly acknowledged?\n",
    "\n",
    "++ Relevance to Education & Policy\n",
    "- Does the poster speak to the FIETS context?\n",
    "- Are implications for education and decision-makers made explicit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
